{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1F40LY38_vmVd4f0-9V_gfe3YPyuUG1pY",
      "authorship_tag": "ABX9TyNnMFCIyFU1rh6y3WTjG/1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DreamSki/DEAP--emotion-classifier/blob/main/lstm_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyX0EsPyXrgo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import _pickle as cPickle\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L3AprEREYCO_",
        "outputId": "1586a25b-7b7b-46d8-a42c-893510ca81eb"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVwP44X4YI8p"
      },
      "source": [
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        " \n",
        "if gpus:\n",
        "    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n",
        "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
        "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
        "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
        "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
        "    tf.config.set_visible_devices([gpu0],\"GPU\") "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjT9UPgbZQ5T"
      },
      "source": [
        "assert(tf.test.gpu_device_name())\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "tf.config.optimizer.set_jit(False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ehMQ7yZTp-"
      },
      "source": [
        "deap_dir = \"/content/drive/MyDrive/data_preprocessed_python\"\n",
        "channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baOTCoC9crrK"
      },
      "source": [
        "def load_DEAP(data_dir, n_subjects = 32, only_phys = False, only_EEG = True):\n",
        "    # get all files name to a list\n",
        "    filenames = os.listdir(data_dir)\n",
        "    filepaths = []\n",
        "    for i in filenames:\n",
        "        filepath = data_dir + \"/\" + i\n",
        "        filepaths.append(filepath)\n",
        "    all_data = []\n",
        "    all_labels = []\n",
        "    if n_subjects < 16:\n",
        "        filepaths = filepaths[:n_subjects]\n",
        "    else:\n",
        "        filepaths = filepaths[-n_subjects:]\n",
        "    print(len(filepaths))\n",
        "    for filepath in filepaths:\n",
        "        loaddata = cPickle.load(open(filepath, 'rb'), encoding=\"latin1\",)\n",
        "        labels = loaddata['labels']\n",
        "        new_data = loaddata['data'].astype(np.float32)\n",
        "        if only_phys:\n",
        "            new_data = new_data[:, 32:, :]\n",
        "        elif only_EEG:\n",
        "            #print(new_data.head())\n",
        "            new_data = new_data[:, channel, :]\n",
        "        all_labels.append(labels)\n",
        "        all_data.append(new_data)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_data = np.array(all_data)\n",
        "\n",
        "    all_data = all_data.reshape(-1, 14, all_data.shape[-1])\n",
        "    all_data = all_data[:, :, 3*128:]\n",
        "    all_labels = all_labels.reshape(-1, all_labels.shape[-1])\n",
        "    print(\"data shape: \", all_data.shape)\n",
        "\n",
        "    # all_data = [all_data[:, 128*i: 128*(i+10)] for i in range(6)]\n",
        "    # all_data = np.concatenate((all_data[0], all_data[1], all_data[2], all_data[3], all_data[4], all_data[5]), axis = 0)\n",
        "    # # print(all_labels.shape)\n",
        "    # print(all_data.shape)\n",
        "\n",
        "    return all_data.astype(np.float16), all_labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV5J18XAczld"
      },
      "source": [
        "def feature_extraction(all_data, labels, label_type = 'valence', task = \"R\", C = 14, N = 10, K = 8, L = 2):\n",
        "    if label_type == \"valence\":\n",
        "            labels = labels[:, 0].squeeze()\n",
        "    elif label_type == 'arousal':\n",
        "        label = labels[:, 1].squeeze()\n",
        "    # drop data which has label == 5\n",
        "    hl_indices = np.where(labels != 5)\n",
        "    labels = labels[hl_indices]\n",
        "    all_data = all_data[hl_indices]\n",
        "    n_samples = 8*32\n",
        "\n",
        "    all_segmented_data = []\n",
        "    for r in range(0, len(all_data), n_samples):\n",
        "        print(r + n_samples, len(all_data))\n",
        "        if r + n_samples < len(all_data):\n",
        "            data = all_data[r: r+n_samples]\n",
        "        else:\n",
        "            data = all_data[r:]\n",
        "        data = data[:, :, :int(data.shape[-1]/L)*L]\n",
        "        \n",
        "        # reshape: original shape: (_, C, 8064) -> (_, C, t * N * K, L) 前后两段\n",
        "        data = data.reshape(data.shape[0], data.shape[1], -1, L)\n",
        "        \n",
        "        # calculate single channel feature (it's the mean value)\n",
        "        data = np.mean(data, axis = -1).squeeze()\n",
        "        \n",
        "        # reshape : original shape: (_, C, N*K, 1) -> (_, C, t * N, K)\n",
        "        data = data.reshape(data.shape[0], data.shape[1], -1, K)\n",
        "        # segmenting ovelap: overlap ratio = (N-1)/N\n",
        "        segmented_data = []\n",
        "        for i in range(0, data.shape[-2] - N, 1):  # ( _, N , C , K)\n",
        "            segmented_data.append(np.transpose(data[:, :, i:i+N, :], (0, 2, 1, 3)))\n",
        "        # reshape to calculate cov matrix\n",
        "        segmented_data = np.array(segmented_data).reshape(-1, C, K)\n",
        "        print(segmented_data.shape)\n",
        "        # calculate pearson corvariance matrix\n",
        "        segmented_corr = tfp.stats.correlation(\n",
        "            segmented_data, y = None, sample_axis=-1, event_axis=-2, keepdims=False, name=None\n",
        "        )\n",
        "        # output = np.array(output).reshape(-1, C*C)\n",
        "        all_segmented_data.append(np.array(segmented_corr))\n",
        "\n",
        "    all_segmented_data = np.concatenate(all_segmented_data, axis = 0 )\n",
        "    upper_indices = np.triu_indices_from(np.ndarray((C, C)), k=1)\n",
        "    sample_matrix = np.arange(0, C*C).reshape((C, C))\n",
        "    upper_values  = list(sample_matrix[upper_indices])\n",
        "    all_segmented_data = all_segmented_data.reshape(-1, N, C*C)\n",
        "    output = all_segmented_data[:, :, upper_values]\n",
        "    print(output.shape)\n",
        "    # output = []\n",
        "\n",
        "    # for i in range(len(all_segmented_data)):\n",
        "    #     # get only the upper triangular of the covariance matrix)\n",
        "    #     cov_matrix = all_segmented_data[i]\n",
        "    #     output.append(list(cov_matrix[upper_indices]))\n",
        "\n",
        "    # output = np.array(output).reshape(int(len(all_segmented_data)/N), N, -1)\n",
        "\n",
        "    if task == 'C':\n",
        "        labels = np.where(labels > 5, 1, 0)\n",
        "    segmented_labels = np.repeat(labels, repeats = int(output.shape[0]/len(labels)), axis = 0)\n",
        "    print(segmented_labels)\n",
        "    return output, np.array(segmented_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1TVd38jc1Mx",
        "outputId": "8629b640-4b16-4ebb-abc1-b9205d727e03"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "!pip install tensorflow-addons\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Input\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from dataset_prepare import load_DEAP, feature_extraction\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 491 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 501 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 512 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 532 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 542 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 563 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 573 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 583 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 593 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 604 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 614 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 634 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 645 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 665 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 675 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 686 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 696 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 706 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 716 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 737 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 747 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 768 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 778 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 788 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 808 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 819 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 829 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 839 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 849 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 860 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 870 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 880 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 890 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 911 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 921 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 942 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 952 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 962 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 983 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 993 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmKG0K8Rc364"
      },
      "source": [
        "\n",
        "def generate_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((10,91)),\n",
        "    tf.keras.layers.LSTM(units = 256 ,activation= 'relu', kernel_initializer=tf.keras.initializers.VarianceScaling(), return_sequences= True),\n",
        "    #tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.LSTM(units = 256 ,activation= 'relu',kernel_initializer=tf.keras.initializers.VarianceScaling(), return_sequences= False),\n",
        "    # Softmax should be done in float32 for numeric stability.\n",
        "    #tf.keras.layers.Activation('sigmoid', dtype='float32'),\n",
        "    tf.keras.layers.Dense(1, activation = \"sigmoid\", kernel_initializer = tf.keras.initializers.GlorotNormal())\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z8oViaT0fzw",
        "outputId": "c5a714c2-ad29-4dd3-9bf2-88ab55d3b234"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 14, 7680)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1oAXnN_c63L",
        "outputId": "50abf491-e0bf-49d3-ced5-e6562a64fc7d"
      },
      "source": [
        "task = \"C\"\n",
        "data, labels = load_DEAP(deap_dir, n_subjects = 32)\n",
        "output, out_labels = feature_extraction(data, labels, label_type = 'valence', task = task, L = 8)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "data shape:  (1280, 14, 7680)\n",
            "256 1264\n",
            "(281600, 14, 8)\n",
            "512 1264\n",
            "(281600, 14, 8)\n",
            "768 1264\n",
            "(281600, 14, 8)\n",
            "1024 1264\n",
            "(281600, 14, 8)\n",
            "1280 1264\n",
            "(264000, 14, 8)\n",
            "(139040, 10, 91)\n",
            "[1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMA2dabec-aZ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(output, out_labels, stratify = out_labels, test_size = 0.2, shuffle = True, random_state = 42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcJ1SQlYdpuZ"
      },
      "source": [
        "def compile_model(model):\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "  model.compile(loss = \"binary_crossentropy\",metrics = [\"accuracy\"], optimizer = opt)\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, x_train, y_train, x_test, y_test, epochs=50):\n",
        "  model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
        "\n",
        "def warmup(model, x_train, y_train, x_test, y_test):\n",
        "  # Warm up the JIT, we do not wish to measure the compilation time.\n",
        "  initial_weights = model.get_weights()\n",
        "  train_model(model, x_train, y_train, x_test, y_test, epochs=1)\n",
        "  model.set_weights(initial_weights)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3uch1hSpIAI",
        "outputId": "8ce76630-35ae-4f82-96fd-8eb02e5129f2"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.config.optimizer.set_jit(True) # Enable XLA.\n",
        "model = compile_model(generate_model())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9B-073gsyRn"
      },
      "source": [
        "assert(tf.test.gpu_device_name())"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lopBoW55fcG5"
      },
      "source": [
        "warmup(model, X_train, y_train, X_test, y_test)\n",
        "%time train_model(model, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWWBkgoupoJ2"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_qf3W57_20l"
      },
      "source": [
        "from scipy import signal"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bFeL8Ay_tld"
      },
      "source": [
        "def bandpass_filter(data, fs=128, low=4, high=45): #no reference for freq    \n",
        "    nyq = 0.5 * fs\n",
        "    low = low / nyq\n",
        "    high = high / nyq\n",
        "    \n",
        "    try:\n",
        "        assert len(data.shape) == 2\n",
        "    except:\n",
        "        print(\"Error: please check data shape, it should be 2D array of a raw signal (nsamples, 3000).\")\n",
        "        raise ValueError\n",
        "\n",
        "    order = 2\n",
        "    b, a = signal.butter(order, [low, high], btype='band')\n",
        "    tmp = signal.filtfilt(b, a, np.concatenate(data))\n",
        "    \n",
        "    return tmp.reshape((data.shape[0], data.shape[1]))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXVIIbRRyLuS"
      },
      "source": [
        "my_data = []\n",
        "for i in range(12):\n",
        "  mydata = pd.read_excel(\"/content/drive/MyDrive/EEG Raw Data/Trail\"+str(i+1)+\".xlsx\",header=1)\n",
        "  a = bandpass_filter(np.array(mydata[ch])[:7428]).tolist()\n",
        "  \n",
        "  my_data.append(a)\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A7lga3d0Dr6"
      },
      "source": [
        "ch = ['EEG.AF3','EEG.F3','EEG.F7','EEG.FC5','EEG.T7','EEG.P7','EEG.O1','EEG.AF4','EEG.F4','EEG.F8','EEG.FC6','EEG.T8','EEG.P8','EEG.O2']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "828lAMmG8AWf"
      },
      "source": [
        "me_data = np.array(my_data)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb3nTf4D7ivE"
      },
      "source": [
        "z=pd.read_csv(\"/content/drive/MyDrive/selfassessmentmanikin/data/selfassessmentmanikin_raw_2021.08.18_2021-08-18-06-40-12-878.iqdat\",sep=\"\\t\")"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KhDRCVH9bsM",
        "outputId": "3949a5cc-63d6-42da-d38e-448acc273aad"
      },
      "source": [
        "z.columns"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['build', 'computer.platform', 'date', 'time', 'subject', 'group',\n",
              "       'sessionid', 'blockcode', 'blocknum', 'trialcode', 'trialnum',\n",
              "       'trialCount', 'targetIndex', 'target', 'valenceSelected',\n",
              "       'arousalSelected', 'rt'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXFvL-rM9hhk"
      },
      "source": [
        "label = np.array(z[[\"valenceSelected\",\"arousalSelected\"]])"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7kLZoZW-O2A",
        "outputId": "ca712687-2388-4f3e-8611-1d794e736fd8"
      },
      "source": [
        "output, out_labels = feature_extraction(me_data1, label, label_type = 'valence', task = task, L = 8)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256 10\n",
            "(10600, 14, 8)\n",
            "(1060, 10, 91)\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga8yEJxh-W9b"
      },
      "source": [
        "me_data1 = me_data.transpose(0,2,1)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtxPv3pS-kgl",
        "outputId": "80db57f4-0de8-4ed9-f3cb-2ade316ef25d"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1060, 10, 91)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Irw5ABX-5qK",
        "outputId": "9de62d02-fedc-4db4-aafb-14b1367def09"
      },
      "source": [
        "out_labels.shape"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1060,)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buUeZ9kL-9Jf",
        "outputId": "82582571-4b59-4792-8597-c4c1fb64539f"
      },
      "source": [
        "model.evaluate(output,out_labels)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 0s 13ms/step - loss: 6.2409 - accuracy: 0.5896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.240941524505615, 0.5896226763725281]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    }
  ]
}